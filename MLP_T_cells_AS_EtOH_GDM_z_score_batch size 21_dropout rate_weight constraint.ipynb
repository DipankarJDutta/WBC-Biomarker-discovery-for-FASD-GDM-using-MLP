{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP_T-cells_AS_EtOH-GDM_z-score.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DipankarJDutta/WBC-Biomarker-ID-for-FASD-GDM-/blob/Optimal-Dropout-rate-for-MLP-model/MLP_T_cells_AS_EtOH_GDM_z_score_batch%20size%2021_dropout%20rate_weight%20constraint.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86TLkXaLMzkK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Loading essentials\n",
        "import numpy\n",
        "from numpy import loadtxt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.constraints import maxnorm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf2BdOONOrca",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load z-scored inclevel values of significantly AS genes in T-cells common to EtOH & GDM datasets\n",
        "dataset = loadtxt ('z-score_T-cell.csv', delimiter = ',')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYDe7ikEO-q0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#split dataset into input and output variables (25 input, 1 output)\n",
        "x = dataset [:, 0:25]\n",
        "y = dataset [:, 25]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIhgfFm9PDdS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define the keras DL model: Input layer: 25; 2 hidden layers; Hidden layer 1: 12 neurons; Hidden layer 2: 8 neurons; Output layer: 1\n",
        "model = Sequential ()\n",
        "dropout_rate = 0.5\n",
        "weight_constraint = 3\n",
        "model.add(Dense(12, input_dim=25, activation='relu', kernel_constraint=maxnorm(weight_constraint)))\n",
        "model.add(Dropout(dropout_rate))\n",
        "model.add(Dense(8, activation='relu', kernel_constraint=maxnorm(weight_constraint)))\n",
        "model.add(Dropout(dropout_rate))\n",
        "model.add(Dense(1, kernel_initializer='glorot_uniform', activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cdclkz3PQ52",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#compile the keras DL model \n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIRDdz_RPc76",
        "colab_type": "code",
        "outputId": "67091143-15ca-4945-93f4-f047f136abbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Train the model with an epoch of 100, a batch size of 21, a validation split of 80-20)\n",
        "model.fit(x, y, validation_split = 0.2, epochs=100, batch_size=21)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 38 samples, validate on 10 samples\n",
            "Epoch 1/100\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 0.9635 - acc: 0.4474 - val_loss: 0.7503 - val_acc: 0.4000\n",
            "Epoch 2/100\n",
            "38/38 [==============================] - 0s 246us/step - loss: 0.8851 - acc: 0.5000 - val_loss: 0.7493 - val_acc: 0.4000\n",
            "Epoch 3/100\n",
            "38/38 [==============================] - 0s 247us/step - loss: 0.8703 - acc: 0.5789 - val_loss: 0.7483 - val_acc: 0.4000\n",
            "Epoch 4/100\n",
            "38/38 [==============================] - 0s 316us/step - loss: 0.8955 - acc: 0.4474 - val_loss: 0.7485 - val_acc: 0.4000\n",
            "Epoch 5/100\n",
            "38/38 [==============================] - 0s 223us/step - loss: 0.9743 - acc: 0.3684 - val_loss: 0.7481 - val_acc: 0.4000\n",
            "Epoch 6/100\n",
            "38/38 [==============================] - 0s 207us/step - loss: 0.8523 - acc: 0.3947 - val_loss: 0.7477 - val_acc: 0.4000\n",
            "Epoch 7/100\n",
            "38/38 [==============================] - 0s 209us/step - loss: 0.8600 - acc: 0.5263 - val_loss: 0.7469 - val_acc: 0.4000\n",
            "Epoch 8/100\n",
            "38/38 [==============================] - 0s 240us/step - loss: 0.8129 - acc: 0.4211 - val_loss: 0.7457 - val_acc: 0.4000\n",
            "Epoch 9/100\n",
            "38/38 [==============================] - 0s 192us/step - loss: 0.8562 - acc: 0.5526 - val_loss: 0.7443 - val_acc: 0.4000\n",
            "Epoch 10/100\n",
            "38/38 [==============================] - 0s 223us/step - loss: 0.9630 - acc: 0.3947 - val_loss: 0.7431 - val_acc: 0.4000\n",
            "Epoch 11/100\n",
            "38/38 [==============================] - 0s 199us/step - loss: 0.8831 - acc: 0.4474 - val_loss: 0.7416 - val_acc: 0.4000\n",
            "Epoch 12/100\n",
            "38/38 [==============================] - 0s 222us/step - loss: 0.6733 - acc: 0.7368 - val_loss: 0.7401 - val_acc: 0.4000\n",
            "Epoch 13/100\n",
            "38/38 [==============================] - 0s 229us/step - loss: 0.8201 - acc: 0.5263 - val_loss: 0.7389 - val_acc: 0.5000\n",
            "Epoch 14/100\n",
            "38/38 [==============================] - 0s 212us/step - loss: 1.0306 - acc: 0.4474 - val_loss: 0.7378 - val_acc: 0.5000\n",
            "Epoch 15/100\n",
            "38/38 [==============================] - 0s 236us/step - loss: 0.8808 - acc: 0.5789 - val_loss: 0.7365 - val_acc: 0.5000\n",
            "Epoch 16/100\n",
            "38/38 [==============================] - 0s 237us/step - loss: 0.9134 - acc: 0.2895 - val_loss: 0.7353 - val_acc: 0.5000\n",
            "Epoch 17/100\n",
            "38/38 [==============================] - 0s 205us/step - loss: 0.8617 - acc: 0.3684 - val_loss: 0.7340 - val_acc: 0.5000\n",
            "Epoch 18/100\n",
            "38/38 [==============================] - 0s 207us/step - loss: 0.7640 - acc: 0.5263 - val_loss: 0.7326 - val_acc: 0.5000\n",
            "Epoch 19/100\n",
            "38/38 [==============================] - 0s 196us/step - loss: 0.9182 - acc: 0.3684 - val_loss: 0.7313 - val_acc: 0.6000\n",
            "Epoch 20/100\n",
            "38/38 [==============================] - 0s 206us/step - loss: 0.8194 - acc: 0.3947 - val_loss: 0.7304 - val_acc: 0.5000\n",
            "Epoch 21/100\n",
            "38/38 [==============================] - 0s 267us/step - loss: 0.7321 - acc: 0.5000 - val_loss: 0.7293 - val_acc: 0.5000\n",
            "Epoch 22/100\n",
            "38/38 [==============================] - 0s 378us/step - loss: 0.8361 - acc: 0.5000 - val_loss: 0.7286 - val_acc: 0.5000\n",
            "Epoch 23/100\n",
            "38/38 [==============================] - 0s 284us/step - loss: 0.7843 - acc: 0.4474 - val_loss: 0.7282 - val_acc: 0.5000\n",
            "Epoch 24/100\n",
            "38/38 [==============================] - 0s 284us/step - loss: 0.9107 - acc: 0.3421 - val_loss: 0.7279 - val_acc: 0.5000\n",
            "Epoch 25/100\n",
            "38/38 [==============================] - 0s 276us/step - loss: 0.8083 - acc: 0.5263 - val_loss: 0.7277 - val_acc: 0.5000\n",
            "Epoch 26/100\n",
            "38/38 [==============================] - 0s 243us/step - loss: 0.7862 - acc: 0.5000 - val_loss: 0.7275 - val_acc: 0.5000\n",
            "Epoch 27/100\n",
            "38/38 [==============================] - 0s 361us/step - loss: 0.9210 - acc: 0.3158 - val_loss: 0.7273 - val_acc: 0.5000\n",
            "Epoch 28/100\n",
            "38/38 [==============================] - 0s 243us/step - loss: 0.7927 - acc: 0.5000 - val_loss: 0.7271 - val_acc: 0.5000\n",
            "Epoch 29/100\n",
            "38/38 [==============================] - 0s 310us/step - loss: 0.6666 - acc: 0.6316 - val_loss: 0.7267 - val_acc: 0.5000\n",
            "Epoch 30/100\n",
            "38/38 [==============================] - 0s 307us/step - loss: 0.7748 - acc: 0.6053 - val_loss: 0.7263 - val_acc: 0.4000\n",
            "Epoch 31/100\n",
            "38/38 [==============================] - 0s 202us/step - loss: 0.7346 - acc: 0.5789 - val_loss: 0.7259 - val_acc: 0.4000\n",
            "Epoch 32/100\n",
            "38/38 [==============================] - 0s 144us/step - loss: 0.7844 - acc: 0.4474 - val_loss: 0.7257 - val_acc: 0.4000\n",
            "Epoch 33/100\n",
            "38/38 [==============================] - 0s 172us/step - loss: 0.7046 - acc: 0.6053 - val_loss: 0.7255 - val_acc: 0.4000\n",
            "Epoch 34/100\n",
            "38/38 [==============================] - 0s 200us/step - loss: 0.7336 - acc: 0.5526 - val_loss: 0.7250 - val_acc: 0.4000\n",
            "Epoch 35/100\n",
            "38/38 [==============================] - 0s 170us/step - loss: 0.8382 - acc: 0.6316 - val_loss: 0.7246 - val_acc: 0.4000\n",
            "Epoch 36/100\n",
            "38/38 [==============================] - 0s 180us/step - loss: 0.6553 - acc: 0.4737 - val_loss: 0.7240 - val_acc: 0.4000\n",
            "Epoch 37/100\n",
            "38/38 [==============================] - 0s 240us/step - loss: 0.7444 - acc: 0.5000 - val_loss: 0.7233 - val_acc: 0.4000\n",
            "Epoch 38/100\n",
            "38/38 [==============================] - 0s 260us/step - loss: 0.8570 - acc: 0.4474 - val_loss: 0.7228 - val_acc: 0.4000\n",
            "Epoch 39/100\n",
            "38/38 [==============================] - 0s 176us/step - loss: 0.7141 - acc: 0.6316 - val_loss: 0.7222 - val_acc: 0.4000\n",
            "Epoch 40/100\n",
            "38/38 [==============================] - 0s 229us/step - loss: 0.7061 - acc: 0.6053 - val_loss: 0.7218 - val_acc: 0.4000\n",
            "Epoch 41/100\n",
            "38/38 [==============================] - 0s 270us/step - loss: 0.7125 - acc: 0.3947 - val_loss: 0.7210 - val_acc: 0.4000\n",
            "Epoch 42/100\n",
            "38/38 [==============================] - 0s 240us/step - loss: 0.7313 - acc: 0.5789 - val_loss: 0.7200 - val_acc: 0.4000\n",
            "Epoch 43/100\n",
            "38/38 [==============================] - 0s 480us/step - loss: 0.7468 - acc: 0.5526 - val_loss: 0.7194 - val_acc: 0.4000\n",
            "Epoch 44/100\n",
            "38/38 [==============================] - 0s 255us/step - loss: 0.8193 - acc: 0.5526 - val_loss: 0.7189 - val_acc: 0.4000\n",
            "Epoch 45/100\n",
            "38/38 [==============================] - 0s 239us/step - loss: 0.7823 - acc: 0.4737 - val_loss: 0.7183 - val_acc: 0.5000\n",
            "Epoch 46/100\n",
            "38/38 [==============================] - 0s 213us/step - loss: 0.6535 - acc: 0.5526 - val_loss: 0.7177 - val_acc: 0.5000\n",
            "Epoch 47/100\n",
            "38/38 [==============================] - 0s 253us/step - loss: 0.6568 - acc: 0.6316 - val_loss: 0.7171 - val_acc: 0.5000\n",
            "Epoch 48/100\n",
            "38/38 [==============================] - 0s 250us/step - loss: 0.7588 - acc: 0.4474 - val_loss: 0.7165 - val_acc: 0.5000\n",
            "Epoch 49/100\n",
            "38/38 [==============================] - 0s 301us/step - loss: 0.8551 - acc: 0.4211 - val_loss: 0.7160 - val_acc: 0.5000\n",
            "Epoch 50/100\n",
            "38/38 [==============================] - 0s 257us/step - loss: 0.6845 - acc: 0.4474 - val_loss: 0.7155 - val_acc: 0.5000\n",
            "Epoch 51/100\n",
            "38/38 [==============================] - 0s 264us/step - loss: 0.8064 - acc: 0.3684 - val_loss: 0.7149 - val_acc: 0.5000\n",
            "Epoch 52/100\n",
            "38/38 [==============================] - 0s 261us/step - loss: 0.7423 - acc: 0.6053 - val_loss: 0.7144 - val_acc: 0.5000\n",
            "Epoch 53/100\n",
            "38/38 [==============================] - 0s 268us/step - loss: 0.6933 - acc: 0.7105 - val_loss: 0.7136 - val_acc: 0.5000\n",
            "Epoch 54/100\n",
            "38/38 [==============================] - 0s 204us/step - loss: 0.7683 - acc: 0.5000 - val_loss: 0.7132 - val_acc: 0.5000\n",
            "Epoch 55/100\n",
            "38/38 [==============================] - 0s 269us/step - loss: 0.7311 - acc: 0.4474 - val_loss: 0.7125 - val_acc: 0.5000\n",
            "Epoch 56/100\n",
            "38/38 [==============================] - 0s 232us/step - loss: 0.6796 - acc: 0.5263 - val_loss: 0.7120 - val_acc: 0.5000\n",
            "Epoch 57/100\n",
            "38/38 [==============================] - 0s 244us/step - loss: 0.7671 - acc: 0.3947 - val_loss: 0.7117 - val_acc: 0.5000\n",
            "Epoch 58/100\n",
            "38/38 [==============================] - 0s 240us/step - loss: 0.7740 - acc: 0.5526 - val_loss: 0.7113 - val_acc: 0.5000\n",
            "Epoch 59/100\n",
            "38/38 [==============================] - 0s 217us/step - loss: 0.6583 - acc: 0.6316 - val_loss: 0.7109 - val_acc: 0.5000\n",
            "Epoch 60/100\n",
            "38/38 [==============================] - 0s 304us/step - loss: 0.7829 - acc: 0.5789 - val_loss: 0.7106 - val_acc: 0.5000\n",
            "Epoch 61/100\n",
            "38/38 [==============================] - 0s 268us/step - loss: 0.6783 - acc: 0.4211 - val_loss: 0.7102 - val_acc: 0.5000\n",
            "Epoch 62/100\n",
            "38/38 [==============================] - 0s 282us/step - loss: 0.7118 - acc: 0.5789 - val_loss: 0.7099 - val_acc: 0.5000\n",
            "Epoch 63/100\n",
            "38/38 [==============================] - 0s 225us/step - loss: 0.7559 - acc: 0.6579 - val_loss: 0.7095 - val_acc: 0.5000\n",
            "Epoch 64/100\n",
            "38/38 [==============================] - 0s 281us/step - loss: 0.6688 - acc: 0.6316 - val_loss: 0.7091 - val_acc: 0.5000\n",
            "Epoch 65/100\n",
            "38/38 [==============================] - 0s 275us/step - loss: 0.7514 - acc: 0.5000 - val_loss: 0.7085 - val_acc: 0.5000\n",
            "Epoch 66/100\n",
            "38/38 [==============================] - 0s 303us/step - loss: 0.6788 - acc: 0.5526 - val_loss: 0.7079 - val_acc: 0.5000\n",
            "Epoch 67/100\n",
            "38/38 [==============================] - 0s 292us/step - loss: 0.7276 - acc: 0.3947 - val_loss: 0.7074 - val_acc: 0.5000\n",
            "Epoch 68/100\n",
            "38/38 [==============================] - 0s 300us/step - loss: 0.6896 - acc: 0.5526 - val_loss: 0.7068 - val_acc: 0.5000\n",
            "Epoch 69/100\n",
            "38/38 [==============================] - 0s 307us/step - loss: 0.6949 - acc: 0.5000 - val_loss: 0.7063 - val_acc: 0.5000\n",
            "Epoch 70/100\n",
            "38/38 [==============================] - 0s 251us/step - loss: 0.7077 - acc: 0.6579 - val_loss: 0.7060 - val_acc: 0.6000\n",
            "Epoch 71/100\n",
            "38/38 [==============================] - 0s 238us/step - loss: 0.7284 - acc: 0.6053 - val_loss: 0.7057 - val_acc: 0.6000\n",
            "Epoch 72/100\n",
            "38/38 [==============================] - 0s 263us/step - loss: 0.7269 - acc: 0.6316 - val_loss: 0.7054 - val_acc: 0.6000\n",
            "Epoch 73/100\n",
            "38/38 [==============================] - 0s 270us/step - loss: 0.6426 - acc: 0.5263 - val_loss: 0.7052 - val_acc: 0.6000\n",
            "Epoch 74/100\n",
            "38/38 [==============================] - 0s 273us/step - loss: 0.7371 - acc: 0.5263 - val_loss: 0.7050 - val_acc: 0.6000\n",
            "Epoch 75/100\n",
            "38/38 [==============================] - 0s 313us/step - loss: 0.6639 - acc: 0.5526 - val_loss: 0.7047 - val_acc: 0.6000\n",
            "Epoch 76/100\n",
            "38/38 [==============================] - 0s 348us/step - loss: 0.6667 - acc: 0.6316 - val_loss: 0.7044 - val_acc: 0.6000\n",
            "Epoch 77/100\n",
            "38/38 [==============================] - 0s 244us/step - loss: 0.6595 - acc: 0.6053 - val_loss: 0.7041 - val_acc: 0.6000\n",
            "Epoch 78/100\n",
            "38/38 [==============================] - 0s 196us/step - loss: 0.7275 - acc: 0.6316 - val_loss: 0.7039 - val_acc: 0.6000\n",
            "Epoch 79/100\n",
            "38/38 [==============================] - 0s 227us/step - loss: 0.6825 - acc: 0.6579 - val_loss: 0.7035 - val_acc: 0.6000\n",
            "Epoch 80/100\n",
            "38/38 [==============================] - 0s 240us/step - loss: 0.7611 - acc: 0.5000 - val_loss: 0.7031 - val_acc: 0.6000\n",
            "Epoch 81/100\n",
            "38/38 [==============================] - 0s 250us/step - loss: 0.6535 - acc: 0.6316 - val_loss: 0.7028 - val_acc: 0.6000\n",
            "Epoch 82/100\n",
            "38/38 [==============================] - 0s 254us/step - loss: 0.7955 - acc: 0.5000 - val_loss: 0.7025 - val_acc: 0.6000\n",
            "Epoch 83/100\n",
            "38/38 [==============================] - 0s 220us/step - loss: 0.6826 - acc: 0.5000 - val_loss: 0.7023 - val_acc: 0.6000\n",
            "Epoch 84/100\n",
            "38/38 [==============================] - 0s 250us/step - loss: 0.6665 - acc: 0.6053 - val_loss: 0.7022 - val_acc: 0.6000\n",
            "Epoch 85/100\n",
            "38/38 [==============================] - 0s 244us/step - loss: 0.7433 - acc: 0.6053 - val_loss: 0.7021 - val_acc: 0.6000\n",
            "Epoch 86/100\n",
            "38/38 [==============================] - 0s 229us/step - loss: 0.7410 - acc: 0.4211 - val_loss: 0.7019 - val_acc: 0.6000\n",
            "Epoch 87/100\n",
            "38/38 [==============================] - 0s 252us/step - loss: 0.6150 - acc: 0.7632 - val_loss: 0.7017 - val_acc: 0.6000\n",
            "Epoch 88/100\n",
            "38/38 [==============================] - 0s 234us/step - loss: 0.6370 - acc: 0.6053 - val_loss: 0.7014 - val_acc: 0.6000\n",
            "Epoch 89/100\n",
            "38/38 [==============================] - 0s 242us/step - loss: 0.6652 - acc: 0.6053 - val_loss: 0.7010 - val_acc: 0.6000\n",
            "Epoch 90/100\n",
            "38/38 [==============================] - 0s 254us/step - loss: 0.6657 - acc: 0.6842 - val_loss: 0.7008 - val_acc: 0.6000\n",
            "Epoch 91/100\n",
            "38/38 [==============================] - 0s 204us/step - loss: 0.6859 - acc: 0.5789 - val_loss: 0.7007 - val_acc: 0.6000\n",
            "Epoch 92/100\n",
            "38/38 [==============================] - 0s 291us/step - loss: 0.6758 - acc: 0.6053 - val_loss: 0.7003 - val_acc: 0.6000\n",
            "Epoch 93/100\n",
            "38/38 [==============================] - 0s 271us/step - loss: 0.8240 - acc: 0.6053 - val_loss: 0.7000 - val_acc: 0.6000\n",
            "Epoch 94/100\n",
            "38/38 [==============================] - 0s 217us/step - loss: 0.6921 - acc: 0.4474 - val_loss: 0.6998 - val_acc: 0.6000\n",
            "Epoch 95/100\n",
            "38/38 [==============================] - 0s 227us/step - loss: 0.6242 - acc: 0.6316 - val_loss: 0.6997 - val_acc: 0.6000\n",
            "Epoch 96/100\n",
            "38/38 [==============================] - 0s 246us/step - loss: 0.6638 - acc: 0.6579 - val_loss: 0.6994 - val_acc: 0.6000\n",
            "Epoch 97/100\n",
            "38/38 [==============================] - 0s 497us/step - loss: 0.6889 - acc: 0.6053 - val_loss: 0.6991 - val_acc: 0.6000\n",
            "Epoch 98/100\n",
            "38/38 [==============================] - 0s 268us/step - loss: 0.7383 - acc: 0.6053 - val_loss: 0.6987 - val_acc: 0.7000\n",
            "Epoch 99/100\n",
            "38/38 [==============================] - 0s 180us/step - loss: 0.7059 - acc: 0.6316 - val_loss: 0.6983 - val_acc: 0.7000\n",
            "Epoch 100/100\n",
            "38/38 [==============================] - 0s 365us/step - loss: 0.6152 - acc: 0.6053 - val_loss: 0.6979 - val_acc: 0.7000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdfb0d21710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2fcujpXPlMu",
        "colab_type": "code",
        "outputId": "a8fbd848-b375-4c51-c0ed-b77e57c4a8cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Evaluate the accuracy of the Keras model with #10-fold cross-validation\n",
        "scores = model.evaluate(x, y, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "acc: 70.83%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjV0AFryPmMB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Save model and architecture to a single file\n",
        "model.save(\"DL_T-cells_21batch\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}