{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP_T-cells_AS_EtOH-GDM_z-score.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DipankarJDutta/WBC-Biomarker-ID-for-FASD-GDM-/blob/Optimal-Neuron-Activation-function-for-MLP-Model/MLP_T_cells_AS_EtOH_GDM_z_score_batch%20size%2021_tanh%20activation%20function.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86TLkXaLMzkK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Loading essentials\n",
        "from numpy import loadtxt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf2BdOONOrca",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load z-scored inclevel values of significantly AS genes in T-cells common to EtOH & GDM datasets\n",
        "dataset = loadtxt ('z-score_T-cell.csv', delimiter = ',')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYDe7ikEO-q0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#split dataset into input and output variables (25 input, 1 output)\n",
        "x = dataset [:, 0:25]\n",
        "y = dataset [:, 25]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIhgfFm9PDdS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define the keras DL model: Input layer: 25; 2 hidden layers; Hidden layer 1: 12 neurons; Hidden layer 2: 8 neurons; Output layer: 1\n",
        "model = Sequential ()\n",
        "model.add(Dense(12, input_dim=25, activation='tanh'))\n",
        "model.add(Dense(8, activation='tanh'))\n",
        "model.add(Dense(1, activation='tanh'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cdclkz3PQ52",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#compile the keras DL model \n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIRDdz_RPc76",
        "colab_type": "code",
        "outputId": "a3d0653a-52e7-41c5-a107-3666be4c1515",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Train the model with an epoch of 100, a batch size of 21, a validation split of 80-20)\n",
        "model.fit(x, y, validation_split = 0.2, epochs=100, batch_size=21)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 38 samples, validate on 10 samples\n",
            "Epoch 1/100\n",
            "38/38 [==============================] - 1s 17ms/step - loss: 3.9758 - acc: 0.4474 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 2/100\n",
            "38/38 [==============================] - 0s 160us/step - loss: 3.9130 - acc: 0.4474 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 3/100\n",
            "38/38 [==============================] - 0s 216us/step - loss: 3.8950 - acc: 0.4474 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 4/100\n",
            "38/38 [==============================] - 0s 138us/step - loss: 3.8820 - acc: 0.4737 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 5/100\n",
            "38/38 [==============================] - 0s 164us/step - loss: 3.5821 - acc: 0.4737 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 6/100\n",
            "38/38 [==============================] - 0s 398us/step - loss: 3.5145 - acc: 0.4737 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 7/100\n",
            "38/38 [==============================] - 0s 221us/step - loss: 3.4734 - acc: 0.4737 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 8/100\n",
            "38/38 [==============================] - 0s 177us/step - loss: 3.4581 - acc: 0.4737 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 9/100\n",
            "38/38 [==============================] - 0s 176us/step - loss: 3.4429 - acc: 0.5000 - val_loss: 12.8945 - val_acc: 0.2000\n",
            "Epoch 10/100\n",
            "38/38 [==============================] - 0s 269us/step - loss: 3.4315 - acc: 0.5000 - val_loss: 12.8946 - val_acc: 0.2000\n",
            "Epoch 11/100\n",
            "38/38 [==============================] - 0s 241us/step - loss: 3.4215 - acc: 0.5000 - val_loss: 12.8960 - val_acc: 0.2000\n",
            "Epoch 12/100\n",
            "38/38 [==============================] - 0s 237us/step - loss: 3.4109 - acc: 0.5000 - val_loss: 12.8972 - val_acc: 0.2000\n",
            "Epoch 13/100\n",
            "38/38 [==============================] - 0s 224us/step - loss: 3.4040 - acc: 0.5000 - val_loss: 12.8983 - val_acc: 0.2000\n",
            "Epoch 14/100\n",
            "38/38 [==============================] - 0s 245us/step - loss: 3.3954 - acc: 0.5000 - val_loss: 12.8994 - val_acc: 0.2000\n",
            "Epoch 15/100\n",
            "38/38 [==============================] - 0s 219us/step - loss: 3.3872 - acc: 0.5000 - val_loss: 12.9004 - val_acc: 0.2000\n",
            "Epoch 16/100\n",
            "38/38 [==============================] - 0s 197us/step - loss: 3.3801 - acc: 0.5000 - val_loss: 11.7479 - val_acc: 0.2000\n",
            "Epoch 17/100\n",
            "38/38 [==============================] - 0s 185us/step - loss: 3.3740 - acc: 0.5000 - val_loss: 10.7288 - val_acc: 0.2000\n",
            "Epoch 18/100\n",
            "38/38 [==============================] - 0s 176us/step - loss: 3.3662 - acc: 0.5000 - val_loss: 10.6132 - val_acc: 0.2000\n",
            "Epoch 19/100\n",
            "38/38 [==============================] - 0s 173us/step - loss: 3.3602 - acc: 0.5000 - val_loss: 10.5588 - val_acc: 0.2000\n",
            "Epoch 20/100\n",
            "38/38 [==============================] - 0s 262us/step - loss: 3.3542 - acc: 0.5000 - val_loss: 10.5152 - val_acc: 0.2000\n",
            "Epoch 21/100\n",
            "38/38 [==============================] - 0s 210us/step - loss: 3.3477 - acc: 0.5263 - val_loss: 10.4957 - val_acc: 0.2000\n",
            "Epoch 22/100\n",
            "38/38 [==============================] - 0s 187us/step - loss: 3.3422 - acc: 0.5263 - val_loss: 10.4662 - val_acc: 0.2000\n",
            "Epoch 23/100\n",
            "38/38 [==============================] - 0s 180us/step - loss: 3.3362 - acc: 0.5263 - val_loss: 10.4594 - val_acc: 0.2000\n",
            "Epoch 24/100\n",
            "38/38 [==============================] - 0s 179us/step - loss: 3.3304 - acc: 0.5263 - val_loss: 10.4478 - val_acc: 0.2000\n",
            "Epoch 25/100\n",
            "38/38 [==============================] - 0s 233us/step - loss: 3.3237 - acc: 0.5263 - val_loss: 10.4459 - val_acc: 0.2000\n",
            "Epoch 26/100\n",
            "38/38 [==============================] - 0s 183us/step - loss: 3.3185 - acc: 0.5263 - val_loss: 10.4356 - val_acc: 0.2000\n",
            "Epoch 27/100\n",
            "38/38 [==============================] - 0s 249us/step - loss: 3.3121 - acc: 0.5263 - val_loss: 10.4352 - val_acc: 0.2000\n",
            "Epoch 28/100\n",
            "38/38 [==============================] - 0s 268us/step - loss: 3.3069 - acc: 0.5263 - val_loss: 10.4582 - val_acc: 0.2000\n",
            "Epoch 29/100\n",
            "38/38 [==============================] - 0s 215us/step - loss: 3.3010 - acc: 0.5263 - val_loss: 10.4707 - val_acc: 0.2000\n",
            "Epoch 30/100\n",
            "38/38 [==============================] - 0s 201us/step - loss: 3.2953 - acc: 0.5263 - val_loss: 10.4751 - val_acc: 0.2000\n",
            "Epoch 31/100\n",
            "38/38 [==============================] - 0s 306us/step - loss: 3.2905 - acc: 0.5526 - val_loss: 10.5381 - val_acc: 0.2000\n",
            "Epoch 32/100\n",
            "38/38 [==============================] - 0s 177us/step - loss: 3.2838 - acc: 0.5526 - val_loss: 10.6494 - val_acc: 0.2000\n",
            "Epoch 33/100\n",
            "38/38 [==============================] - 0s 172us/step - loss: 3.2791 - acc: 0.5526 - val_loss: 11.4703 - val_acc: 0.2000\n",
            "Epoch 34/100\n",
            "38/38 [==============================] - 0s 330us/step - loss: 3.2740 - acc: 0.5789 - val_loss: 11.4670 - val_acc: 0.2000\n",
            "Epoch 35/100\n",
            "38/38 [==============================] - 0s 358us/step - loss: 3.2698 - acc: 0.5789 - val_loss: 11.4641 - val_acc: 0.2000\n",
            "Epoch 36/100\n",
            "38/38 [==============================] - 0s 238us/step - loss: 3.2652 - acc: 0.5789 - val_loss: 11.4616 - val_acc: 0.2000\n",
            "Epoch 37/100\n",
            "38/38 [==============================] - 0s 268us/step - loss: 3.2610 - acc: 0.5789 - val_loss: 11.4594 - val_acc: 0.2000\n",
            "Epoch 38/100\n",
            "38/38 [==============================] - 0s 229us/step - loss: 3.2570 - acc: 0.5789 - val_loss: 11.4574 - val_acc: 0.2000\n",
            "Epoch 39/100\n",
            "38/38 [==============================] - 0s 264us/step - loss: 3.2528 - acc: 0.5789 - val_loss: 11.4557 - val_acc: 0.2000\n",
            "Epoch 40/100\n",
            "38/38 [==============================] - 0s 233us/step - loss: 3.2484 - acc: 0.5789 - val_loss: 11.4542 - val_acc: 0.2000\n",
            "Epoch 41/100\n",
            "38/38 [==============================] - 0s 188us/step - loss: 3.2445 - acc: 0.6053 - val_loss: 11.4528 - val_acc: 0.2000\n",
            "Epoch 42/100\n",
            "38/38 [==============================] - 0s 187us/step - loss: 3.2411 - acc: 0.6316 - val_loss: 11.4517 - val_acc: 0.2000\n",
            "Epoch 43/100\n",
            "38/38 [==============================] - 0s 275us/step - loss: 3.2378 - acc: 0.6316 - val_loss: 11.4506 - val_acc: 0.2000\n",
            "Epoch 44/100\n",
            "38/38 [==============================] - 0s 188us/step - loss: 3.2341 - acc: 0.6316 - val_loss: 11.4497 - val_acc: 0.2000\n",
            "Epoch 45/100\n",
            "38/38 [==============================] - 0s 332us/step - loss: 3.2306 - acc: 0.6579 - val_loss: 11.4487 - val_acc: 0.2000\n",
            "Epoch 46/100\n",
            "38/38 [==============================] - 0s 234us/step - loss: 3.2268 - acc: 0.6579 - val_loss: 11.4481 - val_acc: 0.2000\n",
            "Epoch 47/100\n",
            "38/38 [==============================] - 0s 192us/step - loss: 3.2238 - acc: 0.6579 - val_loss: 11.4473 - val_acc: 0.2000\n",
            "Epoch 48/100\n",
            "38/38 [==============================] - 0s 201us/step - loss: 3.2206 - acc: 0.6579 - val_loss: 11.4465 - val_acc: 0.2000\n",
            "Epoch 49/100\n",
            "38/38 [==============================] - 0s 220us/step - loss: 3.2168 - acc: 0.6579 - val_loss: 11.4458 - val_acc: 0.2000\n",
            "Epoch 50/100\n",
            "38/38 [==============================] - 0s 198us/step - loss: 3.2138 - acc: 0.6579 - val_loss: 11.4450 - val_acc: 0.2000\n",
            "Epoch 51/100\n",
            "38/38 [==============================] - 0s 195us/step - loss: 3.2109 - acc: 0.6579 - val_loss: 11.4443 - val_acc: 0.2000\n",
            "Epoch 52/100\n",
            "38/38 [==============================] - 0s 200us/step - loss: 3.2072 - acc: 0.6579 - val_loss: 11.4437 - val_acc: 0.2000\n",
            "Epoch 53/100\n",
            "38/38 [==============================] - 0s 210us/step - loss: 3.2041 - acc: 0.6579 - val_loss: 11.4431 - val_acc: 0.2000\n",
            "Epoch 54/100\n",
            "38/38 [==============================] - 0s 362us/step - loss: 3.2014 - acc: 0.6579 - val_loss: 11.4426 - val_acc: 0.2000\n",
            "Epoch 55/100\n",
            "38/38 [==============================] - 0s 203us/step - loss: 3.1978 - acc: 0.6579 - val_loss: 11.4420 - val_acc: 0.2000\n",
            "Epoch 56/100\n",
            "38/38 [==============================] - 0s 176us/step - loss: 3.1957 - acc: 0.6579 - val_loss: 11.4414 - val_acc: 0.2000\n",
            "Epoch 57/100\n",
            "38/38 [==============================] - 0s 163us/step - loss: 3.1927 - acc: 0.6579 - val_loss: 11.4407 - val_acc: 0.2000\n",
            "Epoch 58/100\n",
            "38/38 [==============================] - 0s 180us/step - loss: 3.1893 - acc: 0.6842 - val_loss: 11.4403 - val_acc: 0.2000\n",
            "Epoch 59/100\n",
            "38/38 [==============================] - 0s 157us/step - loss: 3.1863 - acc: 0.6842 - val_loss: 11.4396 - val_acc: 0.2000\n",
            "Epoch 60/100\n",
            "38/38 [==============================] - 0s 194us/step - loss: 3.1841 - acc: 0.7105 - val_loss: 11.4391 - val_acc: 0.2000\n",
            "Epoch 61/100\n",
            "38/38 [==============================] - 0s 241us/step - loss: 3.1810 - acc: 0.7105 - val_loss: 11.4386 - val_acc: 0.2000\n",
            "Epoch 62/100\n",
            "38/38 [==============================] - 0s 233us/step - loss: 3.1781 - acc: 0.7105 - val_loss: 11.4381 - val_acc: 0.2000\n",
            "Epoch 63/100\n",
            "38/38 [==============================] - 0s 201us/step - loss: 3.1755 - acc: 0.7105 - val_loss: 11.4377 - val_acc: 0.2000\n",
            "Epoch 64/100\n",
            "38/38 [==============================] - 0s 197us/step - loss: 3.1729 - acc: 0.7105 - val_loss: 11.4372 - val_acc: 0.2000\n",
            "Epoch 65/100\n",
            "38/38 [==============================] - 0s 200us/step - loss: 3.1700 - acc: 0.7105 - val_loss: 11.4366 - val_acc: 0.2000\n",
            "Epoch 66/100\n",
            "38/38 [==============================] - 0s 216us/step - loss: 3.1672 - acc: 0.7105 - val_loss: 11.4361 - val_acc: 0.2000\n",
            "Epoch 67/100\n",
            "38/38 [==============================] - 0s 223us/step - loss: 3.1647 - acc: 0.7105 - val_loss: 11.4357 - val_acc: 0.2000\n",
            "Epoch 68/100\n",
            "38/38 [==============================] - 0s 247us/step - loss: 3.1619 - acc: 0.7105 - val_loss: 11.4352 - val_acc: 0.2000\n",
            "Epoch 69/100\n",
            "38/38 [==============================] - 0s 228us/step - loss: 3.1592 - acc: 0.7105 - val_loss: 11.4347 - val_acc: 0.2000\n",
            "Epoch 70/100\n",
            "38/38 [==============================] - 0s 229us/step - loss: 3.1568 - acc: 0.7105 - val_loss: 11.4343 - val_acc: 0.2000\n",
            "Epoch 71/100\n",
            "38/38 [==============================] - 0s 179us/step - loss: 3.1541 - acc: 0.7105 - val_loss: 11.4339 - val_acc: 0.2000\n",
            "Epoch 72/100\n",
            "38/38 [==============================] - 0s 271us/step - loss: 3.1518 - acc: 0.7105 - val_loss: 11.4334 - val_acc: 0.2000\n",
            "Epoch 73/100\n",
            "38/38 [==============================] - 0s 189us/step - loss: 3.1493 - acc: 0.7105 - val_loss: 11.4330 - val_acc: 0.2000\n",
            "Epoch 74/100\n",
            "38/38 [==============================] - 0s 343us/step - loss: 3.1465 - acc: 0.7368 - val_loss: 11.4327 - val_acc: 0.2000\n",
            "Epoch 75/100\n",
            "38/38 [==============================] - 0s 202us/step - loss: 3.1439 - acc: 0.7368 - val_loss: 11.4324 - val_acc: 0.2000\n",
            "Epoch 76/100\n",
            "38/38 [==============================] - 0s 225us/step - loss: 3.1414 - acc: 0.7368 - val_loss: 11.4321 - val_acc: 0.2000\n",
            "Epoch 77/100\n",
            "38/38 [==============================] - 0s 211us/step - loss: 3.1394 - acc: 0.7368 - val_loss: 11.4317 - val_acc: 0.2000\n",
            "Epoch 78/100\n",
            "38/38 [==============================] - 0s 196us/step - loss: 3.1370 - acc: 0.7368 - val_loss: 11.4315 - val_acc: 0.2000\n",
            "Epoch 79/100\n",
            "38/38 [==============================] - 0s 191us/step - loss: 3.1348 - acc: 0.7368 - val_loss: 11.4311 - val_acc: 0.2000\n",
            "Epoch 80/100\n",
            "38/38 [==============================] - 0s 201us/step - loss: 2.8601 - acc: 0.7368 - val_loss: 11.4308 - val_acc: 0.2000\n",
            "Epoch 81/100\n",
            "38/38 [==============================] - 0s 174us/step - loss: 2.7406 - acc: 0.7368 - val_loss: 11.4306 - val_acc: 0.2000\n",
            "Epoch 82/100\n",
            "38/38 [==============================] - 0s 215us/step - loss: 2.7326 - acc: 0.7368 - val_loss: 11.4304 - val_acc: 0.2000\n",
            "Epoch 83/100\n",
            "38/38 [==============================] - 0s 237us/step - loss: 2.3912 - acc: 0.7368 - val_loss: 11.4307 - val_acc: 0.2000\n",
            "Epoch 84/100\n",
            "38/38 [==============================] - 0s 180us/step - loss: 2.3450 - acc: 0.7632 - val_loss: 11.4311 - val_acc: 0.2000\n",
            "Epoch 85/100\n",
            "38/38 [==============================] - 0s 237us/step - loss: 2.3304 - acc: 0.7632 - val_loss: 11.4316 - val_acc: 0.2000\n",
            "Epoch 86/100\n",
            "38/38 [==============================] - 0s 227us/step - loss: 2.3227 - acc: 0.7632 - val_loss: 11.4321 - val_acc: 0.2000\n",
            "Epoch 87/100\n",
            "38/38 [==============================] - 0s 211us/step - loss: 2.3177 - acc: 0.7632 - val_loss: 11.4326 - val_acc: 0.2000\n",
            "Epoch 88/100\n",
            "38/38 [==============================] - 0s 191us/step - loss: 2.3146 - acc: 0.7632 - val_loss: 11.4331 - val_acc: 0.2000\n",
            "Epoch 89/100\n",
            "38/38 [==============================] - 0s 204us/step - loss: 2.3102 - acc: 0.7632 - val_loss: 11.4335 - val_acc: 0.2000\n",
            "Epoch 90/100\n",
            "38/38 [==============================] - 0s 209us/step - loss: 2.3079 - acc: 0.7895 - val_loss: 11.4339 - val_acc: 0.2000\n",
            "Epoch 91/100\n",
            "38/38 [==============================] - 0s 224us/step - loss: 2.3051 - acc: 0.7895 - val_loss: 11.4343 - val_acc: 0.2000\n",
            "Epoch 92/100\n",
            "38/38 [==============================] - 0s 192us/step - loss: 2.3028 - acc: 0.7895 - val_loss: 10.4143 - val_acc: 0.2000\n",
            "Epoch 93/100\n",
            "38/38 [==============================] - 0s 211us/step - loss: 2.3008 - acc: 0.7895 - val_loss: 10.2911 - val_acc: 0.2000\n",
            "Epoch 94/100\n",
            "38/38 [==============================] - 0s 204us/step - loss: 2.2987 - acc: 0.7895 - val_loss: 10.2432 - val_acc: 0.2000\n",
            "Epoch 95/100\n",
            "38/38 [==============================] - 0s 244us/step - loss: 2.2967 - acc: 0.8158 - val_loss: 10.2130 - val_acc: 0.2000\n",
            "Epoch 96/100\n",
            "38/38 [==============================] - 0s 222us/step - loss: 2.2946 - acc: 0.8158 - val_loss: 10.1940 - val_acc: 0.2000\n",
            "Epoch 97/100\n",
            "38/38 [==============================] - 0s 231us/step - loss: 2.2930 - acc: 0.8158 - val_loss: 10.1799 - val_acc: 0.2000\n",
            "Epoch 98/100\n",
            "38/38 [==============================] - 0s 201us/step - loss: 2.2915 - acc: 0.8158 - val_loss: 10.1680 - val_acc: 0.2000\n",
            "Epoch 99/100\n",
            "38/38 [==============================] - 0s 223us/step - loss: 2.2896 - acc: 0.8158 - val_loss: 10.1586 - val_acc: 0.2000\n",
            "Epoch 100/100\n",
            "38/38 [==============================] - 0s 220us/step - loss: 2.2877 - acc: 0.8158 - val_loss: 10.1503 - val_acc: 0.2000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdd008100b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2fcujpXPlMu",
        "colab_type": "code",
        "outputId": "75e2f209-6327-4fcc-8ed6-a1a1e486294d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Evaluate the accuracy of the Keras model with #10-fold cross-validation\n",
        "scores = model.evaluate(x, y, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "acc: 68.75%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}